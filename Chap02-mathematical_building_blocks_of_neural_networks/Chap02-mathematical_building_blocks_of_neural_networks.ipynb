{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap02 - 시작하기 전에: 신경망의 수학적 구성요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 신경망과의 첫 만남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6-tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 MNIST 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape : (60000, 28, 28)\n",
      "train_labels.shape : (60000,)\n",
      "test_images.shape : (10000, 28, 28)\n",
      "test_labels.shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print('train_images.shape :', train_images.shape)\n",
    "print('train_labels.shape :', train_labels.shape)\n",
    "print('test_images.shape :', test_images.shape)\n",
    "print('test_labels.shape :', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape : (60000, 784)\n",
      "train_labels.shape : (60000,)\n",
      "test_images.shape : (10000, 784)\n",
      "test_labels.shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "# pre-processing\n",
    "train_images = train_images.reshape([-1, 28*28])\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape([-1, 28*28])\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "print('train_images.shape :', train_images.shape)\n",
    "print('train_labels.shape :', train_labels.shape)\n",
    "print('test_images.shape :', test_images.shape)\n",
    "print('test_labels.shape :', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# model\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# compile\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# summary\n",
    "# network.get_input_shape_at(0)\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2533 - acc: 0.9277\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1029 - acc: 0.9695\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0680 - acc: 0.9792\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0492 - acc: 0.9852\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0367 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1346a09ef98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "network.fit(x=train_images, y=train_labels, epochs=5, batch_size=128)  # batch_size : default=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 69us/step\n",
      "test_loss : 0.06694, test_acc : 0.9793\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_loss : {:.5f}, test_acc : {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.10210228430726165&quot;).pbtxt = 'node {\\n  name: &quot;dense_input&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.06804138422012329\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.06804138422012329\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;dense/kernel&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense/kernel&quot;\\n}\\nnode {\\n  name: &quot;dense/kernel/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  input: &quot;dense/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/kernel/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/bias&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;dense/bias&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/bias/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense/bias&quot;\\n}\\nnode {\\n  name: &quot;dense/bias/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  input: &quot;dense/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/bias/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/MatMul/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense_input&quot;\\n  input: &quot;dense/MatMul/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/BiasAdd/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dense/MatMul&quot;\\n  input: &quot;dense/BiasAdd/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dense/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.10721125453710556\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10721125453710556\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;dense_1/kernel&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  input: &quot;dense_1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/kernel/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/bias&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;dense_1/bias&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/bias/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n}\\nnode {\\n  name: &quot;dense_1/bias/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  input: &quot;dense_1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/bias/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/MatMul/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense/Relu&quot;\\n  input: &quot;dense_1/MatMul/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/BiasAdd/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dense_1/MatMul&quot;\\n  input: &quot;dense_1/BiasAdd/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;dense_1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/lr/Initializer/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/lr&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;RMSprop/lr&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/lr/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n}\\nnode {\\n  name: &quot;RMSprop/lr/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  input: &quot;RMSprop/lr/Initializer/initial_value&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/lr&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/lr/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/lr&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/rho/Initializer/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/rho&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;RMSprop/rho&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/rho/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n}\\nnode {\\n  name: &quot;RMSprop/rho/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  input: &quot;RMSprop/rho/Initializer/initial_value&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/rho&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/rho/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/rho&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/decay/Initializer/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/decay&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;RMSprop/decay&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/decay/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/decay&quot;\\n}\\nnode {\\n  name: &quot;RMSprop/decay/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;RMSprop/decay&quot;\\n  input: &quot;RMSprop/decay/Initializer/initial_value&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/decay&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/decay/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/decay&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/decay&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/iterations/Initializer/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/iterations&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;RMSprop/iterations&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/iterations/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n}\\nnode {\\n  name: &quot;RMSprop/iterations/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n  input: &quot;RMSprop/iterations/Initializer/initial_value&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/iterations&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSprop/iterations/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@RMSprop/iterations&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1_target&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense_1_sample_weights&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss/dense_1_loss/sub/x&quot;\\n  input: &quot;loss/dense_1_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  input: &quot;loss/dense_1_loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;loss/dense_1_loss/clip_by_value/Minimum&quot;\\n  input: &quot;loss/dense_1_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;loss/dense_1_loss/clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;dense_1_target&quot;\\n  input: &quot;loss/dense_1_loss/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss/dense_1_loss/Reshape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss/dense_1_loss/Log&quot;\\n  input: &quot;loss/dense_1_loss/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/dense_1_loss/Reshape_1&quot;\\n  input: &quot;loss/dense_1_loss/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dense_1_sample_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar/x&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank/Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/rank&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/Switch_1:1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims/Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like/Shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ones_like&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/Switch_1:1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1/Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/DenseToDenseSetOperation&quot;\\n  op: &quot;DenseToDenseSetOperation&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/ExpandDims_1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;set_operation&quot;\\n    value {\\n      s: &quot;a-b&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_indices&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/num_invalid_dims&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/DenseToDenseSetOperation:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/switch_t&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/x&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/num_invalid_dims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/is_same_rank&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Switch_1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Switch_1:1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;weights can not be broadcast to values.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;weights.shape=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;dense_1_sample_weights:0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;values.shape=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/Const_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;is_scalar=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/NoOp&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_t&quot;\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_t&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/NoOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_t&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;weights can not be broadcast to values.&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;weights.shape=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;dense_1_sample_weights:0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;values.shape=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_5&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;is_scalar=&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_0&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_2&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_4&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_5&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_STRING\\n        type: DT_INT32\\n        type: DT_STRING\\n        type: DT_BOOL\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_valid_shape/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/values/shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/is_scalar&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/switch_f&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/control_dependency_1&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Merge&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Merge&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense_1_sample_weights&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/dense_1_loss/Mul&quot;\\n  input: &quot;loss/dense_1_loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights&quot;\\n  input: &quot;loss/dense_1_loss/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;loss/dense_1_loss/Sum&quot;\\n  input: &quot;loss/dense_1_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;loss/dense_1_loss/Sum_1&quot;\\n  input: &quot;loss/dense_1_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/dense_1_loss/Greater&quot;\\n  input: &quot;loss/dense_1_loss/truediv&quot;\\n  input: &quot;loss/dense_1_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/dense_1_loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/dense_1_loss/Select&quot;\\n  input: &quot;loss/dense_1_loss/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss/mul/x&quot;\\n  input: &quot;loss/dense_1_loss/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;dense_1_target&quot;\\n  input: &quot;metrics/acc/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  input: &quot;metrics/acc/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;metrics/acc/ArgMax&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;metrics/acc/Max&quot;\\n  input: &quot;metrics/acc/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;metrics/acc/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/acc/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;metrics/acc/Cast_1&quot;\\n  input: &quot;metrics/acc/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/RMSprop/gradients/Shape&quot;\\n  input: &quot;training/RMSprop/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/Fill&quot;\\n  input: &quot;loss/dense_1_loss/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/Fill&quot;\\n  input: &quot;loss/mul/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/mul_grad/Mul_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Tile&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Select&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/dense_1_loss/Greater&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/truediv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss/dense_1_loss/Greater&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/zeros_like&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/Select&quot;\\n  input: &quot;loss/dense_1_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;loss/dense_1_loss/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Neg&quot;\\n  input: &quot;loss/dense_1_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv_1&quot;\\n  input: &quot;loss/dense_1_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Select_grad/Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Sum_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/truediv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/truediv_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Sum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Sum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Tile&quot;\\n  input: &quot;loss/dense_1_loss/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Mul_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Sum_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Mul_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Reshape_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Reshape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Reshape_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Reshape_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;loss/dense_1_loss/clip_by_value&quot;\\n  input: &quot;^training/RMSprop/gradients/loss/dense_1_loss/Reshape_1_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Log&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Reshape_1_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/Log&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/dense_1_loss/clip_by_value/Minimum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape_2&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;loss/dense_1_loss/clip_by_value/Minimum&quot;\\n  input: &quot;loss/dense_1_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/GreaterEqual&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/GreaterEqual&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/zeros&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/Log_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Select_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Sum_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape_2&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/LessEqual&quot;\\n  op: &quot;LessEqual&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  input: &quot;loss/dense_1_loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/LessEqual&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/LessEqual&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/zeros&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Select&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Select_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Sum_1&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/dense_1_loss/clip_by_value/Minimum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Reshape&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/Softmax&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/Softmax&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/gradients/loss/dense_1_loss/clip_by_value/Minimum_grad/Reshape&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/Softmax&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/sub&quot;\\n  input: &quot;dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/Softmax&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul_1&quot;\\n  input: &quot;dense_1/MatMul/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/MatMul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense/Relu&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/Softmax_grad/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense_1/MatMul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/MatMul_grad/MatMul&quot;\\n  input: &quot;dense/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/Relu&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/RMSprop/gradients/dense/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/BiasAdd&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;training/RMSprop/gradients/dense/Relu_grad/ReluGrad&quot;\\n  input: &quot;dense/MatMul/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/MatMul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/gradients/dense/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense_input&quot;\\n  input: &quot;training/RMSprop/gradients/dense/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense/MatMul&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/RMSprop/zeros/shape_as_tensor&quot;\\n  input: &quot;training/RMSprop/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;training/RMSprop/Variable&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n  input: &quot;training/RMSprop/zeros&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_1&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;training/RMSprop/Variable_1&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_1/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_1/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n  input: &quot;training/RMSprop/zeros_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_1/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros_2/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros_2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros_2&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/RMSprop/zeros_2/shape_as_tensor&quot;\\n  input: &quot;training/RMSprop/zeros_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_2&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;training/RMSprop/Variable_2&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_2/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_2/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n  input: &quot;training/RMSprop/zeros_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_2/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/zeros_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_3&quot;\\n  op: &quot;VarHandleOp&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;training/RMSprop/Variable_3&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_3/IsInitialized/VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_3/Assign&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n  input: &quot;training/RMSprop/zeros_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Variable_3/Read/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/RMSprop/Variable_3&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignAddVariableOp&quot;\\n  op: &quot;AssignAddVariableOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n  input: &quot;training/RMSprop/Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n  input: &quot;^training/RMSprop/AssignAddVariableOp&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_1&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_1&quot;\\n  input: &quot;training/RMSprop/mul/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_2&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/sub/x&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/RMSprop/gradients/dense/MatMul_grad/MatMul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/sub&quot;\\n  input: &quot;training/RMSprop/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/mul&quot;\\n  input: &quot;training/RMSprop/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n  input: &quot;training/RMSprop/add&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_3&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_4&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_4&quot;\\n  input: &quot;training/RMSprop/gradients/dense/MatMul_grad/MatMul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;training/RMSprop/add&quot;\\n  input: &quot;training/RMSprop/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/RMSprop/clip_by_value/Minimum&quot;\\n  input: &quot;training/RMSprop/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;training/RMSprop/clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/Sqrt&quot;\\n  input: &quot;training/RMSprop/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/mul_2&quot;\\n  input: &quot;training/RMSprop/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_5&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_5&quot;\\n  input: &quot;training/RMSprop/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_1&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  input: &quot;training/RMSprop/sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_6&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/kernel&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_7&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_3/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_7&quot;\\n  input: &quot;training/RMSprop/mul_3/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_8&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/sub_2/x&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Square_1&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/RMSprop/gradients/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/sub_2&quot;\\n  input: &quot;training/RMSprop/Square_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/mul_3&quot;\\n  input: &quot;training/RMSprop/mul_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_2&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n  input: &quot;training/RMSprop/add_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_9&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_10&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_10&quot;\\n  input: &quot;training/RMSprop/gradients/dense/BiasAdd_grad/BiasAddGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_1/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;training/RMSprop/add_2&quot;\\n  input: &quot;training/RMSprop/Const_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/RMSprop/clip_by_value_1/Minimum&quot;\\n  input: &quot;training/RMSprop/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Sqrt_1&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;training/RMSprop/clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/Sqrt_1&quot;\\n  input: &quot;training/RMSprop/add_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/mul_5&quot;\\n  input: &quot;training/RMSprop/add_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_11&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_11&quot;\\n  input: &quot;training/RMSprop/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_3&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  input: &quot;training/RMSprop/sub_3&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_12&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense/bias&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_3&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_13&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_6/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_13&quot;\\n  input: &quot;training/RMSprop/mul_6/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_14&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_4/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_4&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/sub_4/x&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Square_2&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/MatMul_grad/MatMul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_7&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/sub_4&quot;\\n  input: &quot;training/RMSprop/Square_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_4&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/mul_6&quot;\\n  input: &quot;training/RMSprop/mul_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_4&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n  input: &quot;training/RMSprop/add_4&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_15&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_4&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_16&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_8&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_16&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/MatMul_grad/MatMul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_2/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;training/RMSprop/add_4&quot;\\n  input: &quot;training/RMSprop/Const_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_2&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/RMSprop/clip_by_value_2/Minimum&quot;\\n  input: &quot;training/RMSprop/Const_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Sqrt_2&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;training/RMSprop/clip_by_value_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_5/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_5&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/Sqrt_2&quot;\\n  input: &quot;training/RMSprop/add_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/truediv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/mul_8&quot;\\n  input: &quot;training/RMSprop/add_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_17&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_5&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_17&quot;\\n  input: &quot;training/RMSprop/truediv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_5&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  input: &quot;training/RMSprop/sub_5&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_18&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_5&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_19&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_9/ReadVariableOp&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_9&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_19&quot;\\n  input: &quot;training/RMSprop/mul_9/ReadVariableOp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_20&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_6/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_6&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/sub_6/x&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_20&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Square_3&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_10&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/sub_6&quot;\\n  input: &quot;training/RMSprop/Square_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_6&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/mul_9&quot;\\n  input: &quot;training/RMSprop/mul_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_6&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n  input: &quot;training/RMSprop/add_6&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_21&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_6&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_22&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/mul_11&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_22&quot;\\n  input: &quot;training/RMSprop/gradients/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_7&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Const_8&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: inf\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_3/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;training/RMSprop/add_6&quot;\\n  input: &quot;training/RMSprop/Const_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/clip_by_value_3&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/RMSprop/clip_by_value_3/Minimum&quot;\\n  input: &quot;training/RMSprop/Const_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/Sqrt_3&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;training/RMSprop/clip_by_value_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_7/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/add_7&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;training/RMSprop/Sqrt_3&quot;\\n  input: &quot;training/RMSprop/add_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/truediv_3&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/RMSprop/mul_11&quot;\\n  input: &quot;training/RMSprop/add_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_23&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/sub_7&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/RMSprop/ReadVariableOp_23&quot;\\n  input: &quot;training/RMSprop/truediv_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/AssignVariableOp_7&quot;\\n  op: &quot;AssignVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  input: &quot;training/RMSprop/sub_7&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/RMSprop/ReadVariableOp_24&quot;\\n  op: &quot;ReadVariableOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n  input: &quot;^training/RMSprop/AssignVariableOp_7&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^loss/mul&quot;\\n  input: &quot;^metrics/acc/Mean&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_12&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_15&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_18&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_21&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_24&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_3&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_6&quot;\\n  input: &quot;^training/RMSprop/ReadVariableOp_9&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/rho&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_1&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/decay&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_2&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_3&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_2&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_4&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_1&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_5&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense_1/kernel&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_6&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;training/RMSprop/Variable_3&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_7&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/lr&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_8&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense/kernel&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_9&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense_1/bias&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_10&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;RMSprop/iterations&quot;\\n}\\nnode {\\n  name: &quot;VarIsInitializedOp_11&quot;\\n  op: &quot;VarIsInitializedOp&quot;\\n  input: &quot;dense/bias&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^RMSprop/decay/Assign&quot;\\n  input: &quot;^RMSprop/iterations/Assign&quot;\\n  input: &quot;^RMSprop/lr/Assign&quot;\\n  input: &quot;^RMSprop/rho/Assign&quot;\\n  input: &quot;^dense/bias/Assign&quot;\\n  input: &quot;^dense/kernel/Assign&quot;\\n  input: &quot;^dense_1/bias/Assign&quot;\\n  input: &quot;^dense_1/kernel/Assign&quot;\\n  input: &quot;^training/RMSprop/Variable/Assign&quot;\\n  input: &quot;^training/RMSprop/Variable_1/Assign&quot;\\n  input: &quot;^training/RMSprop/Variable_2/Assign&quot;\\n  input: &quot;^training/RMSprop/Variable_3/Assign&quot;\\n}\\nnode {\\n  name: &quot;group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^loss/mul&quot;\\n  input: &quot;^metrics/acc/Mean&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.10210228430726165&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from show_graph import show_graph\n",
    "\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Keras vs TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def shuffle_batch(features, labels, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(features))\n",
    "    n_batches = len(features) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        batch_images, batch_labels = features[batch_idx], labels[batch_idx]\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "inputs = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "labels = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "# model\n",
    "network = tf.layers.dense(inputs=inputs, units=512, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(network, 10, activation=None)\n",
    "\n",
    "# loss\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "# optimizer\n",
    "train_op = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "# metrics\n",
    "correct = tf.nn.in_top_k(predictions=logits, targets=labels, k=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - train_loss: 0.0942 - train_acc: 0.9767\n",
      "epoch: 2 - train_loss: 0.0426 - train_acc: 0.9922\n",
      "epoch: 3 - train_loss: 0.0058 - train_acc: 1.0000\n",
      "epoch: 4 - train_loss: 0.0056 - train_acc: 1.0000\n",
      "epoch: 5 - train_loss: 0.0028 - train_acc: 1.0000\n",
      "test_loss: 0.0729 - test_acc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    n_batches = len(train_images) // batch_size\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            batch_images, batch_labels = next(shuffle_batch(train_images, train_labels, batch_size))\n",
    "            sess.run(train_op, feed_dict={inputs: batch_images,\n",
    "                                          labels: batch_labels})\n",
    "        train_loss, train_acc = sess.run([loss, accuracy],\n",
    "                                         feed_dict={inputs: batch_images, labels: batch_labels})\n",
    "        print('\\repoch: {} - train_loss: {:.4f} - train_acc: {:.4f}'.format(epoch+1,\n",
    "                                                                          train_loss,\n",
    "                                                                          train_acc))\n",
    "    # eval\n",
    "    test_loss, test_acc = sess.run([loss, accuracy],\n",
    "                                   feed_dict={inputs: test_images, labels: test_labels})\n",
    "    print('test_loss: {:.4f} - test_acc: {:.4f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/keras.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 신경망을 위한 데이터 표현\n",
    "\n",
    "- 거의 모든 딥러닝 프레임워크는 일반적으로 **텐서(Tensor)**를 기본 데이터 구조로 사용한다.\n",
    "- 텐서는 데이터를 위한 **컨테이너**(container)이다.\n",
    "- 텐서는 임의의 차원(또는 축) 개수를 가지는 행렬의 일반화된 모습이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 스칼라(Scalar, 0D tensor)\n",
    "\n",
    "- 하나의 숫자만 담고 있는 텐서를 **스칼라**(scalar, 또는 스칼라 텐서, 0차원 텐서, 0D 텐서)라고 부른다.\n",
    "- 스칼라 텐서의 차원(축 개수)은 0이다.\n",
    "- NumPy의 `.ndim` 속성을 이용해 차원(축)을 확인할 수 있다. \n",
    "- 텐서의 축 개수를 **랭크(rank)**라고도 부른다.\n",
    "  - 여기서 랭크는 선형대수에서 선형 독립의 개수를 의미하는 계수(rank)와는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : 12\n",
      "x.ndim : 0\n",
      "x.shape : ()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0D Tensor\n",
    "x = np.array(12)\n",
    "print('x : {}\\nx.ndim : {}'.format(x, x.ndim))\n",
    "print('x.shape :', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 벡터 (1D tensor)\n",
    "\n",
    "- 숫자의 배열을 **벡터(vector)** 또는 1D 텐서라고 부른다. \n",
    "- 1D 텐서는 딱 하나의 축(axis)을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [12  3  6 14  7]\n",
      "x.ndim : 1\n",
      "x.shape : (5,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "print('x : {}\\nx.ndim : {}'.format(x, x.ndim))\n",
    "print('x.shape :', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 벡터는 5개의 원소를 가지고 있으므로 5차원 벡터라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector vs. Tensor\n",
    "\n",
    "- Vector ⊂ Matrix ⊂ Tensor\n",
    "- 벡터는 하나의 축을 따라 $N$-개의 차원을 가진 것이고, [텐서](http://sdolnote.tistory.com/entry/WhatisTensor)는 $N$-개의 축을 가진것이다. 텐서의 각 축을 따라 여러 개의 차원을 가진 벡터가 놓일 수 있다.\n",
    "  - 예를들어, RGB 이미지는 3D 텐서이며, 각 축(R, G, B)을 따라 2D 텐서 즉, Matrix를 가진다.\n",
    "- **차원수(dimensionality)**는 벡터 개념에서의 차원처럼 각 축을 따라 놓인 원소의 개수를 의미하기 때문에, 텐서에서는 랭크를 사용하는 것이 기술적으로 좀더 정확하다.\n",
    "  - 예를들어, 5D 텐서의 경우 5차원 텐서 보다는 랭크 5인 텐서라고 말하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 행렬 (2D tensor)\n",
    "\n",
    "- 벡터의 배열을 **행렬**(matrix) 또는 2D 텐서라고 한다. \n",
    "- 아래의 행렬을 NumPy로 나타내면 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 5 & 78 & 2 & 34 & 0 \\\\ 6 & 79 & 3 & 35 & 1 \\\\ 7 & 80 & 4 & 36 & 2 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "[[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 36  2]]\n",
      "x.ndim : 2\n",
      "x.shape : (3, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0], \n",
    "              [6, 79, 3, 35, 1], \n",
    "              [7, 80, 4, 36, 2]])\n",
    "print('x :\\n{}\\nx.ndim : {}'.format(x, x.ndim))\n",
    "print('x.shape :', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 78,  2, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 3D 텐서와 고차원 텐서\n",
    "\n",
    "- 행렬들을 하나의 새로운 배열로 합치면 직육면체의 형태로 해석할 수 있는 3D 텐서가 만들어진다. \n",
    "- 3D 텐서들을 하나의 배열로 합치면 4D 텐서가 되며, 이런식으로 고차원 텐서를 만든다.\n",
    "- 딥러닝에서는 보통 0D ~ 4D 까지의 텐서를 다룬다.\n",
    "\n",
    "![](./images/3d-tensor.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "[[[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]]\n",
      "x.ndim : 3\n",
      "x.shape : (3, 3, 5)\n",
      "x.dtype : int32\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]], \n",
    "              [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]]])\n",
    "print('x :\\n{}\\nx.ndim : {}'.format(x, x.ndim))\n",
    "print('x.shape :', x.shape)\n",
    "print('x.dtype :', x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 핵심 속성\n",
    "\n",
    "- 텐서는 3개의 핵심 속성으로 정의된다.\n",
    "  - **Rank(축의 개수)** : 예를 들어 3D 텐서에는 3개의 축이 있고, 행렬에는 2개의 축이 있다. NumPy의 `.ndim` 을 통해 확인할 수 있다.\n",
    "  - **Shape(형태)** : 텐서의 각 축을  따라 얼마나 많은 차원이 있는지를 나타내는 Python의 tuple이다. NumPy의 `.shape`을 통해 확인할 수 있다.\n",
    "  - **Data type** : 텐서에 포함된 데이터의 타입이다.\n",
    "    - `.dtype`을 통해 확인 가능하다.\n",
    "    - `float32, float64, uint8, int32`등\n",
    "    - 텐서는 사전에 할당되어 메모리에 저장되어야 하기 때문에 가변 길이의 문자열을 지원하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 NumPy로 텐서 조작하기\n",
    "\n",
    "- 배열에 있는 특정 원소들을 선택해는 것을 **슬라이싱(slicing)** 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "[[[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]]\n",
      "x.ndim : 3\n",
      "x.shape : (3, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]], \n",
    "              [[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1], \n",
    "               [7, 80, 4, 36, 2]]])\n",
    "\n",
    "print('x :\\n{}\\nx.ndim : {}'.format(x, x.ndim))\n",
    "print('x.shape :', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_slice.shape : (2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "x_slice = x[:2]\n",
    "print('x_slice.shape :', x_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_slice.shape : (2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "x_slice = x[:2, :, :]\n",
    "print('x_slice.shape :', x_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_slice.shape : (2, 2, 2)\n",
      "x_slice :\n",
      "[[[ 5 78]\n",
      "  [ 6 79]]\n",
      "\n",
      " [[ 5 78]\n",
      "  [ 6 79]]]\n",
      "x_slice.ndim : 3\n"
     ]
    }
   ],
   "source": [
    "x_slice = x[:2, :2, :2]\n",
    "print('x_slice.shape :', x_slice.shape)\n",
    "print('x_slice :\\n{}\\nx_slice.ndim : {}'.format(x_slice, x_slice.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 배치 데이터\n",
    "\n",
    "- 일반적으로 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축은 **샘플 축(sample axis)** 이라고 한다.\n",
    "- 딥러닝 모델은 한 번에 전체 데이터셋을 가지고 학습하지 않고, 전체 데이터셋에서 일부 데이터를 샘플링해 학습하는데, 이를 **배치(batch)** 라고 한다.\n",
    "- 배치 데이터에서 첫 번째 축을 **배치 축(batch axis)** 또는 **배치 차원(batch dimension)**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 텐서의 실제 사례\n",
    "\n",
    "딥러닝에서 자주 사용하게될 텐서는 다음과 같은 것들이 있다.\n",
    "\n",
    "- **벡터 데이터** : `(samples, features)` 형태의 2D 텐서\n",
    "    - (나이, 우편번호, 소득)으로 구성된 통계 데이터, `(N, 3)`\n",
    "- **시계열 데이터** 또는 **시퀀스 데이터** : `(samples, timesteps, features)` 형태의 3D 텐서\n",
    "    - 주식 가격 데이터셋은 (250일치, 하루거래시간(분), (현재, 최소, 최고)) → `(250, 390, 3)` \n",
    "- **이미지** : `(samples, height, width, channels)` 또는 `(samples, channels, height, width)` 형태의 4D 텐서\n",
    "    - MNIST 데이터 셋 (배치, 높이, 너비, 채널) → `(N, 28, 28, 1)` \n",
    "- **동영상** : `(samples, frames, height, width, channels)` 또는 `(samples, frames, channels, height, width)` 형태의 5D 텐서\n",
    "    - 60초 짜리 144$\\times$256 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240 프레임이며, 이런 비디오 클립을 4개 가진 배치는 `(4, 240, 144, 256, 3)` 텐서에 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 원소별(element-wise) 연산\n",
    "\n",
    "- 원소별 연산(element-wise operation)은 텐서에 있는 각 원소에 독립적으로 적용되는 연산을 말한다. \n",
    "- NumPy는 텐서의 원소별 연산을 제공하여 빠르게 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu(x) :\n",
      "[[0 1]\n",
      " [0 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.array([[-1, 1], \n",
    "              [-2, 3]])\n",
    "\n",
    "print('relu(x) :\\n{}'.format(relu(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 브로드캐스팅 (Broadcasting)\n",
    "\n",
    "- Broadcast의 사전적인 의미는 '퍼뜨리다'라는 뜻이 있는데, 이와 마찬가지로 두 텐서 A, B 중 크기가 작은 텐서를 크기가 큰 텐서와 형태(shape)가 맞게끔 늘려주는 것을 의미한다.\n",
    "\n",
    "- 브로드캐스팅은 두 단계로 이루어진다.\n",
    "\n",
    "  - ① 큰 텐서의 랭크(차원)에 맞도록 작은 텐서에 축(axis)이 추가된다.\n",
    "  - ② 작은 텐서가 새 축을 따라서 큰 텐서의 형태에 맞도록 반복된다.\n",
    "\n",
    "\n",
    "![broadcasting](./images/broadcasting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.shape : (3, 3), b.shape : (1,)\n",
      "w.ndim : 2, b.ndim : 1\n",
      "h.ndim : 2\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([[1, 2, 3], \n",
    "              [4, 5, 6], \n",
    "              [7, 8, 9]])\n",
    "b = np.array([1])\n",
    "\n",
    "h = w - b\n",
    "\n",
    "print('w.shape : {}, b.shape : {}'.format(w.shape, b.shape))\n",
    "print('w.ndim : {}, b.ndim : {}'.format(w.ndim, b.ndim))\n",
    "print('h.ndim : {}\\n{}'.format(h.ndim, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3. 텐서 점곱 (tensor dot)\n",
    "\n",
    "- **텐서 곱셈**(tensor product)라고도 한다.\n",
    "\n",
    "- NumPy, Keras에서는 `.dot`을 이용해 텐서 곱셈을 수행한다.\n",
    "- 고차원 텐서 간의 곱셈은 다음과 같이 할 수 있다.\n",
    "  - `(a, b, c, d) ∙ (d,) → (a, b, c)`\n",
    "  - `(a, b, c, d) ∙ (d, e) → (a, b, c, e) `  \n",
    "\n",
    "![](./images/dot.PNG)\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 4 \\\\ 2 & 5 \\\\ 3 & 6 \\end{bmatrix}\\cdot \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}=\\begin{bmatrix} 17 & 22 & 27 \\\\ 22 & 29 & 36 \\\\ 27 & 36 & 45 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : (3, 2), y.shape : (2, 3)\n",
      "z.shape : (3, 3)\n",
      "[[17 22 27]\n",
      " [22 29 36]\n",
      " [27 36 45]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 4], \n",
    "              [2, 5], \n",
    "              [3, 6]])\n",
    "y = np.array([[1, 2, 3], \n",
    "              [4, 5, 6]])\n",
    "\n",
    "z = np.dot(x, y)\n",
    "\n",
    "print('x.shape : {}, y.shape : {}'.format(x.shape, y.shape))\n",
    "print('z.shape : {}\\n{}'.format(z.shape, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17. 22. 27.]\n",
      " [22. 29. 36.]\n",
      " [27. 36. 45.]]\n"
     ]
    }
   ],
   "source": [
    "# in keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "x = K.constant(x)\n",
    "y = K.constant(y)\n",
    "z = K.dot(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    z = z.eval()\n",
    "    \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 텐서 형태 변환\n",
    "\n",
    "- 텐서 형태 변환(tensor reshaping)은 특정 형태에 맞게 행과 열을 재배열 한다는 뜻이다.\n",
    "- NumPy의 `.reshape()`을 이용해 형태를 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : (3, 2)\n",
      "x.shape : (6, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "x.shape : (2, 3)\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "x.shape : (3, 2)\n",
      "[[0 3]\n",
      " [1 4]\n",
      " [2 5]]\n",
      "x.shape : (2, 3)\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[0, 1], \n",
    "              [2, 3], \n",
    "              [4, 5]])\n",
    "\n",
    "print('x.shape :', x.shape)\n",
    "\n",
    "x = x.reshape([6, -1]) # == [6, 1]\n",
    "print('x.shape : {}\\n{}'.format(x.shape, x))\n",
    "\n",
    "x = x.reshape([2, -1]) # == [2, 3]\n",
    "print('x.shape : {}\\n{}'.format(x.shape, x))\n",
    "\n",
    "# Transpose - 1\n",
    "x = np.transpose(x)  # == x.T\n",
    "print('x.shape : {}\\n{}'.format(x.shape, x))\n",
    "\n",
    "# Transpose - 2\n",
    "x = np.transpose(x,  (1, 0))  # == x.T\n",
    "print('x.shape : {}\\n{}'.format(x.shape, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 텐서 연산의 기하학적 해석\n",
    "\n",
    "- 텐서 연산은 일반적으로 아핀변환(affine transformation) 회전, 스케일링(scaling) 등 기본적인 기하학적 연산을 표현할 수 있다.\n",
    "- **Affine transformation** : [아핀 변환](https://en.wikipedia.org/wiki/Affine_transformation)은 점, 직선, 평면을 보존하는 아핀 공간으로의 변환을 의미한다. 이 변환은 거리의 비율과 직선의 평행을 유지하는 이동, 스케일링, 회전 등이 포함된다.\n",
    "  - Affine Space : 아핀공간은 벡터공간을 평행이동한 것이라 할 수 있다. \n",
    "\n",
    "\n",
    "$$\n",
    "\\vec{y} = f(\\vec{x}) = \\mathbf{W}\\vec{x} + \\vec{b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- 따라서, Fully-Connected layer를 **Affine layer**라고도 한다.\n",
    "\n",
    "![](./images/affine.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 그래디언트 기반 최적화\n",
    "\n",
    "- 딥러닝 모델의 학습 초기에는 가중치($\\mathbf{W}$) 파라미터는 랜덤하게 초기화된다. → [여기](http://excelsior-cjh.tistory.com/177?category=940400) 참고\n",
    "- 학습이 진행되면서 [역전파](http://excelsior-cjh.tistory.com/171?category=940400)(backpropagation)에 의해 가중치가 업데이트 된다.\n",
    "- 학습 과정은 다음과 같다. → [여기](http://excelsior-cjh.tistory.com/172?category=940400) 참고\n",
    "\n",
    "1. 먼저, 각 학습 데이터 샘플을 네트워크에 입력으로 넣어주고 출력층까지 각 층의 뉴런 마다 출력을 계산한다. 이를 **순전파**(forward propagation)이라고 한다. \n",
    "\n",
    "2. 그 다음 네트워크의 마지막 출력층에 대한 결과(예측값)와 실제값과의 차이, 즉 오차(error)를 계산하는데, 손실함수(loss function)를 이용하여 계산한다.\n",
    "\n",
    "3. 그리고 이 오차를 역방향으로 흘러 보내면서, 각 출력 뉴런의 오차에 마지막 입력 뉴런이 얼마나 기여했는지 측정한다. 이말을 쉽게 설명하면, **각 뉴런의 입력값에 대한 손실함수의 편미분, 그래디언트(gradient)을 계산**하는 것을 말한다.\n",
    "\n",
    "4. 3번과 같은 방법을 입력층에 도달할 때까지 계속 반복해서 역방향으로 흘러 보낸다.\n",
    "\n",
    "5. 마지막으로, 계산한 그래디언트를 네트워크의 모든 가중치 매개변수에 반영해주는 **경사 하강법 단계**를 수행한다.\n",
    "\n",
    "\n",
    "\n",
    "- **그래디언트**(gradient)는 텐서 연산의 변화율을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 확률적 경사 하강법\n",
    "\n",
    "- 신경망에서의 **경사 하강법**(GD, Gradient Descent)는 손실함수를 최소화하기 위해 반복해서 가중치 파라미터를 조정해 나가는 것이라고 할 수 있다.\n",
    "- 신경망에서는 층이 깊어질수록 가중치 파라미터의 수가 엄청나게 많아지기 때문에 수식을 풀어서 한번에 최적의 값을 찾을 수 없다.\n",
    "- 따라서, 일반적으로 **미니 배치 확률적 경사 하강법**(mini-batch stochastic gradient descent)을 사용한다. \n",
    "- 신경망처럼 고차원 공간에서는 지역 최소값(local minima)은 매우 드물게 나타나며, 대부분 안장점(saddle point)로 나타난다.\n",
    "- 다양한 경사 하강법을 이용하여 손실함수를 최소화 시키는 방법을 최적화 방법(optimization)이라고 한다.\n",
    "- 옵티마이저에는 SGD, Adagrad, RMSProp 등 다양한 옵티마이저가 있다.  → [여기](https://github.com/ExcelsiorCJH/DLFromScratch/blob/master/Chap06-Training_Models/[%EB%B0%91%EB%9F%AC%EB%8B%9D]_Chap06-%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4.pdf) 참고\n",
    "\n",
    "\n",
    "\n",
    "![](./images/op.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 요약\n",
    "\n",
    "- **학습(learning)**은 학습 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화 하는 모델 파라미터의 조합을 찾는 것을 말한다.\n",
    "- 데이터 샘플과 타깃의 배치를 랜덤하게 추출하여 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행된다. 가중치 파라미터는 학습률(learning rate)에 의해 그래디언트 반대 방향으로 조금씩 움직인다.\n",
    "- 전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 때문에 가능하다. \n",
    "- 손실(loss)는 학습하는 동안 최소화해야 할 측정 지표이다.\n",
    "- 옵티마이저(optimizer)는 손실에 대한 그래디언트가 파라미터를 업데이트하는 방식을 정의한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
