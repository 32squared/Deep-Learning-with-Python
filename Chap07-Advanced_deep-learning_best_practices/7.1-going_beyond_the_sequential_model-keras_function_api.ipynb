{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap07 - 딥러닝을 위한 고급 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "- Keras의 함수형 API (Function API)\n",
    "\n",
    "- Keras의 Callback 사용 방법\n",
    " \n",
    "- 시각화 도구인 텐서보드 사용 방법\n",
    "\n",
    "- 최고 수준의 모델을 만들기 위한 모범 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Sequential 모델을 넘어서: 케라스의 함수형 API\n",
    "\n",
    "- [`Sequential`](https://keras.io/models/sequential/) 모델은 네트워크 입력과 출력이 하나라고 가정한다.\n",
    "\n",
    "![](./images/sequential.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Sequential` 모델 클래스는 다음의 상황에는 사용하기 부적합하다.\n",
    "\n",
    "    - 여러 개의 (개별)입력이 필요한 경우\n",
    "    \n",
    "    - 여러 개의 출력이 필요한 경우\n",
    "    \n",
    "    - 층(layer)을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function(함수형) API를 이용하면 위의 모델을 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/multi-io.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception-res.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 함수형 API 소개\n",
    "\n",
    "- [**함수형 API**](https://keras.io/getting-started/functional-api-guide/)(functional API)에서는 직접 텐서들의 입출력을 다룬다.\n",
    "\n",
    "- 함수처럼 층을 사용하여 텐서를 입력받고 출력한다. \n",
    "\n",
    "- 파이썬에는 클래스 객체를 함수처럼 호출할 수 있는 매직 메서드(던더 메서드) `__call__()`메서드를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Relu:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))  # 텐서\n",
    "dense = layers.Dense(32, activation='relu')  # 함수처럼 사용하기 위해 층 객체를 만듦\n",
    "\n",
    "output_tensor = dense(input_tensor)  # 텐서와 함께 층을 호출하면 텐서를 반환한다.\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Sequential` 모델과 함수형 API 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Sequential #\n",
    "##############\n",
    "K.clear_session()\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Functional API #\n",
    "##################\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듦\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스는 `input_tensor`에서 `output_tensor`로 출력되는 데 까지 필요한 모든 층을 추출한 뒤 `Model`객체를 만든다.\n",
    "\n",
    "- `input_tensor`를 반복 변환하여 `output_tensor`를 만들 수 있어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 다중 입력 모델 (Multi-Input Model)\n",
    "\n",
    "- 함수형 API는 다중 입력 모델(multi-input model)을 만드는 데 사용할 수 있다.\n",
    "\n",
    "- 일반적으로 서로 다른 입력을 합치기 위해 여러 텐서를 연결할 수 있는 층(layer)를 사용한다. → [[링크](https://keras.io/layers/merge/)]참고\n",
    "\n",
    "    - `keras.layers.add`, `keras.layers.concatenate` 등이 있다.\n",
    "    \n",
    "   \n",
    "- 예를 들어, 질문-응답(question-answering) 모델을 다음과 같이 구성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/multi-input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 질문-응답 모델의 함수형 API 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     640000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           12416       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          32500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,337,332\n",
      "Trainable params: 1,337,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "# 입력을 shape이 64인 벡터의 시퀀스로 임베딩\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "# LSTM을 사용하여 하나의 벡터로 인코딩\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(text_vocabulary_size, 64)(question_input)\n",
    "# LSTM을 사용하여 하나의 벡터로 인코딩\n",
    "encoded_question = layers.LSTM(32)(embedded_question)\n",
    "\n",
    "# 인코딩된 질문과 텍스트를 연결한다.\n",
    "# concatenated = layers.Concatenate(axis=-1)([encoded_text, encoded_question])\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# 소프트맥스 분류기 추가\n",
    "answer = layers.Dense(answer_vocabulary_size, \n",
    "                      activation='softmax')(concatenated)\n",
    "\n",
    "# 모델 객체를 만들고 2개의 입력과 출력을 주입\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Input 모델에 데이터 주입하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "answers = to_categorical(answers)  # One-hot\n",
    "\n",
    "# 리스트 입력을 사용하여 학습\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# # 입력에 이름(name)을 지정했을 때만 사용가능\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 다중 출력 모델 (Multi-Output Model)\n",
    "\n",
    "- 7.1.2에서 처럼 함수형 API를 사용해 **다중 출력** 모델을 만들 수 있다.\n",
    "\n",
    "- 예를 들어, 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준을 예측하는 모델을 다음과 같이 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/multi-output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3개의 출력을 가진 함수형API 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    163968      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    327936      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 출력 층에 이름을 지정\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',\n",
    "                                 name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input,\n",
    "              [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Output Model의 `compile` 옵션 (1) : 다중 손실"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 출력 모델을 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야 한다.\n",
    "\n",
    "- 위의 예제에서는 각 네트워크 출력에 따른 손실함수를 다음과 같이 지정해줘야 한다.\n",
    "\n",
    "    - 나이 예측은 스칼라 회귀 문제 → `mse`\n",
    "    - 성별 예측은 이진 클래스 문제 → `binary_crossentropy`\n",
    "    - 소득 수준은 다중 클래스 문제 → `categorical_crossentropy`\n",
    "    \n",
    "\n",
    "- 경사 하강법(GD)은 하나의 스칼라 값, 즉 하나의 손실 값을 최소하하기 때문에 모델을 훈련하려면 각 출력에 대한 손실들을 **하나의 값으로 합쳐**줘야 한다. \n",
    "    - 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것이다.\n",
    "\n",
    "\n",
    "- 케라스에서는 `compile()`메서드에 리스트나 딕셔너리를 사용하여 출력마다 다른 손실을 지정할 수 있다.\n",
    "    - 계산된 손실 값은 하나의 전체 손실로 더해지고 훈련을 통해 최소화 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 형태\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# 딕셔너리 형태: 출력 층에 이름을 지정해야함\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Output Model의 `compile` 옵션 (2) : 손실 가중치\n",
    "\n",
    "- 손실(loss)값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화한다.\n",
    "\n",
    "- 이를 해결하기 위해, 각 출력의 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있다.\n",
    "\n",
    "\n",
    "- 특히 손실 값의 **스케일**이 다를 때 유용하다.\n",
    "    - MSE는 일반적으로 3~5 사이의 값을 가지고, CEE는 0.1정도이기 때문에 CEE에는 가중치 10을 주고, MSE에는 가중치 0.25로 설정해 줄 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 형태\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10])\n",
    "\n",
    "# 딕셔너리 형태: 출력 층에 이름을 지정해야함\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Output Model에 데이터 주입하기\n",
    "\n",
    "- Multi-Input 모델과 마찬가지로 넘파이(NumPy) 배열의 리스트나 딕셔너리를 모델에 전달하여 훈련한다.\n",
    "\n",
    "\n",
    "```python\n",
    "# 리스트 형태\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "# 딕셔너리 형태 : 출력 층에 이름을 지정해야 함\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4 층으로 구성된 비순환 유향 그래프\n",
    "\n",
    "- 함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 [토폴로지](https://ko.wikipedia.org/wiki/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC_%ED%86%A0%ED%8F%B4%EB%A1%9C%EC%A7%80)가 복잡한 네트워크도 만들 수 있다.\n",
    "\n",
    "- 케라스의 신경망은 층으로 구성된 어떠한 **비순환 유향 그래프**(directed acyclic graph)를 만들 수 있다. \n",
    "\n",
    "- 그래프로 구현된 신경망 컴포넌트 중 유명한 2개는 **인셉션 모듈(Inception module)**과 **잔차 연결(residual connection)**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인셉션 모듈\n",
    "\n",
    "- [**인셉션(Inception)**](https://arxiv.org/abs/1409.4842)은 합성곱 신경망에서 인기 있는 네트워크 구조이다.\n",
    "\n",
    "- **네트워크 안의 네트워크**(NiN, Network-in-Network) 구조에서 영감을 받아 Szegedy 등이 만들었다.\n",
    "\n",
    "\n",
    "- 가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가진다.\n",
    "\n",
    "    - $1 \\times 1$ 합성곱으로 시작해서 $3 \\times 3$ 합성곱 다음 마지막 전체 출력 특성이 합쳐진다.\n",
    "    \n",
    "        - 일부 가지에서는 $3 \\times 3$ 대신 $5 \\times 5$를 사용하기도 한다.\n",
    "    \n",
    "    \n",
    "    - 이러한 구성은 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 해준다.\n",
    "    \n",
    "- **인셉션 V3**([Inception V3](https://arxiv.org/abs/1512.00567))의 구조는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception-v3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $1 \\times 1$ **합성곱의 목적**\n",
    " - 입력 텐서의 채널(channel) 또는 depth 정보를 혼합한 특성을 계산하며, **공간 방향**으로는 정보를 섞지 않는다. \n",
    " - 채널(depth) 방향의 특성 학습과 공간 방향의 특성 학습을 분리하는 데 도움을 준다.\n",
    " - 채널(depth)의 차원을 줄이는 데 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](./images/bottleneck.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/inception-v3-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수형 API를 이용해 인셉션 모듈 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inception_input (InputLayer)    (None, 28, 28, 256)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 128)  32896       inception_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 128)  32896       inception_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 14, 14, 256)  0           inception_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 128)  32896       inception_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 128)  295040      average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 128)  147584      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 512)  0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14, 14, 10)   5130        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 841,610\n",
      "Trainable params: 841,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(28, 28, 256), dtype='float32', name='inception_input')\n",
    "\n",
    "# 모든 가지는 동일한 스트라이드(2)를 사용 \n",
    "#   → 출력 크기를 동일하게 만들어 하나로 합치기 위함\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, padding='same',\n",
    "                         activation='relu', strides=2)(inputs)\n",
    " \n",
    "branch_b = layers.Conv2D(128, 1, padding='same',\n",
    "                         activation='relu')(inputs)\n",
    "branch_b = layers.Conv2D(128, 3, padding='same',\n",
    "                         activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(inputs)\n",
    "branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(inputs)\n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# Concatenate\n",
    "concatenated = layers.concatenate([branch_a, branch_b, \n",
    "                                   branch_c, branch_d], axis=-1)\n",
    "outputs = layers.Dense(10, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인셉션 V3 전체 구조는 케라스의 `keras.application.inception_v3.InceptionV3`에 포함되어 있다.\n",
    "\n",
    "- 인셉션 모델과 비슷한 모델인 [**엑셉션(Xception)**](https://arxiv.org/abs/1610.02357)도 케라스 애플리케이션 모듈에 포함되어 있다. \n",
    "\n",
    "    - 이 합성곱 구조는 인셉션에서 일부 영감을 받았다.\n",
    "    \n",
    "    - 채널(깊이) 방향의 학습과 공간 방향의 학습을 극단적으로 분리한다는 아이디어에 착안하여 인셉션 모듈을 깊이별 분리 합성곱으로 바꾼다.\n",
    "    \n",
    "    - 각 입력 채널(깊이)에 따로따로 적용되는 공간 방향 합성곱 다음에 $1 \\times 1$ 합성곱을 적용한다.\n",
    "    \n",
    "    - 따라서, 공간 특성과 채널(깊이) 방향 특성을 완전히 분리한다.\n",
    "    \n",
    "    - keras에서 `layers.SeparableConv2D` 합성곱을 사용한다.\n",
    "    \n",
    "    - 엑셉션(Xception)은 Inception V3와 거의 동일한 개수의 파라밑를 가지지만 실행 속도가 더 빠르고, 대규모 데잍셋에서 정확도가 더 높다.\n",
    "    \n",
    " \n",
    "![](./images/depthwise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잔차 연결 (Residual Connection)\n",
    "\n",
    "- 잔차 연결([residual connection](https://arxiv.org/abs/1512.03385))은 그래프 형태의 네트워크 컴포넌트다.\n",
    "\n",
    "\n",
    "- 대규모 딥러닝 모델에서 흔히 나타나는 두 가지 문제인 **그래디언트 소실**과 **표현 병목(representational bottleneck)**을 해결 했다. \n",
    "\n",
    "    - 일반적으로 10개 층 이상을 가진 모델에 잔차 연결을 추가하면 도움이 된다.\n",
    "    \n",
    "\n",
    "- 잔차 연결은 하위 층의 출력을 상위층의 입력으로 사용한다.\n",
    "\n",
    "- 하위 층의 출력이 상위 층의 활성화 출력에 연결되는 것이 아니고 더해지기 때문에, 두 출력의 크기가 동일해야 한다.\n",
    "\n",
    "\n",
    "![](./images/resnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수형 API를 이용한 잔차 연결 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mnist_input (InputLayer)        (None, 28, 28, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 128)  147584      mnist_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 128)  0           conv2d_2[0][0]                   \n",
      "                                                                 mnist_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100352)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1003530     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,298,698\n",
      "Trainable params: 1,298,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "x = Input(shape=(28, 28, 128), name='mnist_input')\n",
    "conv = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "conv = layers.Conv2D(128, 3, activation='relu', padding='same')(conv)\n",
    "\n",
    "# residual connection\n",
    "# = layers.Add()([conv, x])\n",
    "residual = layers.add([conv, x])\n",
    "\n",
    "outputs = layers.Flatten()(residual)\n",
    "outputs = layers.Dense(10, activation='softmax')(outputs)\n",
    "\n",
    "# Model\n",
    "model = Model(x, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 층 가중치 공유\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
